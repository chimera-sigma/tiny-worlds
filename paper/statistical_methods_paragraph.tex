% Statistical Methods Paragraph
% Drop this into your Methods section

\subsection{Statistical evaluation}

All experiments were conducted with 20 independent random seeds per configuration. To assess the statistical significance of predictive gains, we used sign-flip permutation tests with 9,999 resamples. For each configuration, we computed the observed mean $\Delta \mathrm{NLL}$ across seeds, then generated a null distribution by randomly flipping the sign of each seed's $\Delta \mathrm{NLL}$ value and recomputing the mean. The permutation $p$-value is the fraction of permutations yielding a mean as large or larger than the observed value. This approach makes no parametric assumptions about the distribution of $\Delta \mathrm{NLL}$ and is robust to outliers.

With 20 seeds and an approximately normal distribution, this test has greater than 80 percent power to detect effect sizes of order 0.9 standard deviations or larger at $\alpha = 0.05$ (one-tailed). The effect sizes we observe between structured and null worlds are typically much larger (Cohen's $d > 2$ in most cases), placing them well above the detectable threshold. For example, on the oscillator world E3 at $H = 16$, the tanh RNN yields mean $\Delta \mathrm{NLL} \approx 0.65$ with standard deviation $\approx 0.003$, while the null world yields $\Delta \mathrm{NLL} \approx 0.004$ with comparable variance, corresponding to an effect size of hundreds of standard deviations.

For probe performance, we report the coefficient of determination $R^2$ between the probe's predictions and the true latent coordinates (or regime labels). Since the null and permuted probe baselines consistently yield $R^2$ near zero, we do not conduct formal significance tests on probe metrics; the substantive question is whether the trained probe achieves high $R^2$ (above 0.8) in worlds where the latent is informative, which is evident from inspection.

All runs were automatically validated during logging. Runs exhibiting numerical instabilities (NaN or Inf values, or $\Delta \mathrm{NLL}$ below $-100$ for non-scrambled configurations) were flagged as invalid and excluded from aggregation. Fewer than 5 percent of runs were excluded by this criterion, and results are qualitatively unchanged when including all runs.
